import runpod
import torch
import base64
import io
import os
from PIL import Image
from pathlib import Path

# Model imports (IDM-VTON iÃ§in)
from diffusers import StableDiffusionInpaintPipeline
from transformers import CLIPTextModel, CLIPTokenizer
import numpy as np

print("=" * 50)
print("ğŸš€ IDM-VTON Handler BaÅŸlatÄ±lÄ±yor...")
print("=" * 50)

# GPU kontrolÃ¼
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸ“ Device: {device}")

# Model yÃ¼kleme (global - bir kere yÃ¼klenir)
MODEL_LOADED = False
pipe = None

def load_model():
    """Model yÃ¼kleme fonksiyonu"""
    global pipe, MODEL_LOADED
    
    if MODEL_LOADED:
        print("âœ… Model zaten yÃ¼klÃ¼!")
        return
    
    try:
        print("ğŸ“¦ Model yÃ¼kleniyor...")
        
        # IDM-VTON veya alternatif model
        # Buraya kendi modelinizin yÃ¼kleme kodunu ekleyin
        
        # Ã–rnek: Stable Diffusion Inpainting (basit alternatif)
        model_id = "stabilityai/stable-diffusion-2-inpainting"
        pipe = StableDiffusionInpaintPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if device == "cuda" else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        pipe.to(device)
        pipe.enable_attention_slicing()
        
        MODEL_LOADED = True
        print("âœ… Model hazÄ±r!")
        
    except Exception as e:
        print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
        raise

# BaÅŸlangÄ±Ã§ta model yÃ¼kle
load_model()

def base64_to_image(base64_string):
    """Base64 string'i PIL Image'a Ã§evirir"""
    try:
        # data:image/jpeg;base64, prefix'ini temizle
        if ',' in base64_string:
            base64_string = base64_string.split(',')[1]
        
        img_data = base64.b64decode(base64_string)
        img = Image.open(io.BytesIO(img_data)).convert("RGB")
        return img
    except Exception as e:
        print(f"âŒ Base64 decode hatasÄ±: {e}")
        raise

def image_to_base64(img):
    """PIL Image'Ä± base64 string'e Ã§evirir"""
    try:
        buffered = io.BytesIO()
        img.save(buffered, format="JPEG", quality=95)
        img_str = base64.b64encode(buffered.getvalue()).decode()
        return img_str
    except Exception as e:
        print(f"âŒ Image encode hatasÄ±: {e}")
        raise

def process_tryon(human_img, garment_img, garment_des="clothing item"):
    """
    Virtual try-on iÅŸlemini yapar
    
    Args:
        human_img: PIL Image - KiÅŸinin fotoÄŸrafÄ±
        garment_img: PIL Image - KÄ±yafet fotoÄŸrafÄ±
        garment_des: str - KÄ±yafet aÃ§Ä±klamasÄ±
    
    Returns:
        PIL Image - Try-on sonucu
    """
    try:
        print(f"ğŸ¨ Try-on iÅŸlemi baÅŸladÄ±...")
        print(f"   Human: {human_img.size}, Garment: {garment_img.size}")
        
        # GÃ¶rselleri resize et (model iÃ§in optimize boyut)
        target_size = (512, 768)  # width, height
        human_img_resized = human_img.resize(target_size, Image.LANCZOS)
        garment_img_resized = garment_img.resize(target_size, Image.LANCZOS)
        
        # BURAYA GERÃ‡EK IDM-VTON MODELÄ°NÄ°ZÄ° EKLEYIN!
        # Åimdilik basit bir demo implementasyonu:
        
        # Ã–rnek: Basit overlay (gerÃ§ek model yerine)
        # GerÃ§ek IDM-VTON kullanÄ±yorsanÄ±z aÅŸaÄŸÄ±daki kodu deÄŸiÅŸtirin:
        
        with torch.no_grad():
            # Prompt oluÅŸtur
            prompt = f"A person wearing {garment_des}, full body, high quality, detailed"
            
            # Basit mask oluÅŸtur (Ã¼st gÃ¶vde bÃ¶lgesi)
            mask = Image.new("L", target_size, 255)
            
            # Model Ã§alÄ±ÅŸtÄ±r
            if pipe is not None:
                result = pipe(
                    prompt=prompt,
                    image=human_img_resized,
                    mask_image=mask,
                    negative_prompt="blurry, low quality, distorted",
                    num_inference_steps=30,
                    guidance_scale=7.5,
                    strength=0.8
                ).images[0]
            else:
                # Fallback: Basit blend
                result = Image.blend(human_img_resized, garment_img_resized, 0.5)
        
        print("âœ… Try-on tamamlandÄ±!")
        return result
        
    except Exception as e:
        print(f"âŒ Try-on hatasÄ±: {e}")
        # Hata durumunda orijinal gÃ¶rseli dÃ¶ndÃ¼r
        return human_img

def handler(event):
    """
    RunPod handler fonksiyonu
    
    Expected input format:
    {
        "input": {
            "human_img": "base64_string",
            "garm_img": "base64_string",
            "garment_des": "description (optional)",
            "is_checked": true,
            "is_checked_crop": false,
            "denoise_steps": 30,
            "seed": 42
        }
    }
    """
    try:
        print("\n" + "=" * 50)
        print("ğŸ“¥ Yeni istek alÄ±ndÄ±!")
        print("=" * 50)
        
        # Input'larÄ± al
        job_input = event.get('input', {})
        
        human_img_b64 = job_input.get('human_img')
        garm_img_b64 = job_input.get('garm_img')
        garment_des = job_input.get('garment_des', 'clothing item')
        denoise_steps = job_input.get('denoise_steps', 30)
        seed = job_input.get('seed', 42)
        
        # Validasyon
        if not human_img_b64 or not garm_img_b64:
            raise ValueError("human_img ve garm_img gerekli!")
        
        print(f"ğŸ“‹ Parametreler:")
        print(f"   - Garment desc: {garment_des}")
        print(f"   - Denoise steps: {denoise_steps}")
        print(f"   - Seed: {seed}")
        
        # Seed ayarla
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed(seed)
        
        # Base64'ten PIL Image'a Ã§evir
        print("ğŸ”„ GÃ¶rseller decode ediliyor...")
        human_img = base64_to_image(human_img_b64)
        garm_img = base64_to_image(garm_img_b64)
        
        # Try-on iÅŸlemi
        print("ğŸ¨ Try-on iÅŸlemi baÅŸlatÄ±lÄ±yor...")
        result_img = process_tryon(human_img, garm_img, garment_des)
        
        # Sonucu base64'e Ã§evir
        print("ğŸ“¤ SonuÃ§ encode ediliyor...")
        result_b64 = image_to_base64(result_img)
        
        print("âœ… Ä°ÅŸlem baÅŸarÄ±yla tamamlandÄ±!")
        print("=" * 50 + "\n")
        
        return {
            "output": result_b64,
            "status": "success"
        }
        
    except Exception as e:
        error_msg = f"Handler hatasÄ±: {str(e)}"
        print(f"âŒ {error_msg}")
        import traceback
        traceback.print_exc()
        
        return {
            "error": error_msg,
            "status": "failed"
        }

# RunPod serverless baÅŸlat
if __name__ == "__main__":
    print("\n" + "=" * 50)
    print("ğŸ¯ RunPod Serverless Handler HazÄ±r!")
    print("=" * 50 + "\n")
    
    runpod.serverless.start({"handler": handler})
